{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "arranged-continuity",
   "metadata": {},
   "source": [
    "# Regression dengan KNN (K Nearest Neighbours)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turkish-nitrogen",
   "metadata": {},
   "source": [
    "- KNN adalah model machine learning yang dapat digunakan untuk melakukan prediksi berdasarkan kedekatan karakteristik dengan sejumlah tetangga terdekat.\n",
    "- Prediksi yang dilakukan dapat diterapkan baik pada classification maupun regression tasks.\n",
    "\n",
    "Referensi: https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worst-extension",
   "metadata": {},
   "source": [
    "## Sample Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "textile-great",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tinggi</th>\n",
       "      <th>jk</th>\n",
       "      <th>berat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>158</td>\n",
       "      <td>pria</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>170</td>\n",
       "      <td>pria</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>183</td>\n",
       "      <td>pria</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>191</td>\n",
       "      <td>pria</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>155</td>\n",
       "      <td>wanita</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>163</td>\n",
       "      <td>wanita</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>180</td>\n",
       "      <td>wanita</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>158</td>\n",
       "      <td>wanita</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>170</td>\n",
       "      <td>wanita</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tinggi      jk  berat\n",
       "0     158    pria     64\n",
       "1     170    pria     86\n",
       "2     183    pria     84\n",
       "3     191    pria     80\n",
       "4     155  wanita     49\n",
       "5     163  wanita     59\n",
       "6     180  wanita     67\n",
       "7     158  wanita     54\n",
       "8     170  wanita     67"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sensus = {'tinggi': [158, 170, 183, 191, 155, 163, 180, 158, 170], \n",
    "          'jk': ['pria', 'pria', 'pria', 'pria', 'wanita', 'wanita', 'wanita', 'wanita', 'wanita'],\n",
    "          'berat': [64, 86, 84, 80, 49, 59, 67, 54, 67]}\n",
    "\n",
    "sensus_df = pd.DataFrame(sensus)\n",
    "sensus_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "catholic-glory",
   "metadata": {},
   "source": [
    "- Dictionary menampung 3 keys yaitu : 'tinggi', 'jk', 'berat'\n",
    "- 'tinggi' akan berasosiasi dengan nilai tinggi badan\n",
    "- 'jk' akan berasosiasi dengan daftar jenis kelamin\n",
    "- 'berat' akan berasosiasi dengan sekumpulan nilai berat badan\n",
    "- sensus merupakan variabel yang menampung dictionary\n",
    "- pd.DataFrame(sensus) untuk membentuk dictionary sensus menjadi pandas data frame\n",
    "- objek dataframe ditampung dalam variabel sensus_df\n",
    "- data tinggi dan jenis kelamin berperan sebagai features\n",
    "- data berat badan berperan sebagai target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "major-airplane",
   "metadata": {},
   "source": [
    "## Regression dengan KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premier-general",
   "metadata": {},
   "source": [
    "### Features & Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "liable-finish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:\n",
      "[[158 'pria']\n",
      " [170 'pria']\n",
      " [183 'pria']\n",
      " [191 'pria']\n",
      " [155 'wanita']\n",
      " [163 'wanita']\n",
      " [180 'wanita']\n",
      " [158 'wanita']\n",
      " [170 'wanita']]\n",
      "\n",
      "y_train: [64 86 84 80 49 59 67 54 67]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train = np.array(sensus_df[['tinggi', 'jk']])\n",
    "y_train = np.array(sensus_df['berat'])\n",
    "\n",
    "print(f'X_train:\\n{X_train}\\n')\n",
    "print(f'y_train: {y_train}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adopted-pressure",
   "metadata": {},
   "source": [
    "- tinggi badan dan jenis kelamin di set kedalam np.array dan ditampung dalam variabel x_train sebagai features untuk training set\n",
    "- berat badan di set ke dalam np.array dan ditampung dalam variabel y_train sebagai target untuk training set\n",
    "- nilai features sudah termasuk format array dua dimensi dan tipe data numerik"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relative-manufacturer",
   "metadata": {},
   "source": [
    "### Preprocess Dataset: Konversi Label menjadi Numerik Biner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "usual-print",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:\n",
      "[[158 'pria']\n",
      " [170 'pria']\n",
      " [183 'pria']\n",
      " [191 'pria']\n",
      " [155 'wanita']\n",
      " [163 'wanita']\n",
      " [180 'wanita']\n",
      " [158 'wanita']\n",
      " [170 'wanita']]\n",
      "\n",
      "X_train_transposed:\n",
      "[[158 170 183 191 155 163 180 158 170]\n",
      " ['pria' 'pria' 'pria' 'pria' 'wanita' 'wanita' 'wanita' 'wanita'\n",
      "  'wanita']]\n"
     ]
    }
   ],
   "source": [
    "X_train_transposed = np.transpose(X_train)\n",
    "\n",
    "print(f'X_train:\\n{X_train}\\n')\n",
    "print(f'X_train_transposed:\\n{X_train_transposed}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limited-explosion",
   "metadata": {},
   "source": [
    "- Proses transpose mengubah posisi baris menjadi kolom,dan mengubah posisi kolom menjadi baris\n",
    "- Posisi baris mengindikasikan instance\n",
    "- Posisi kolom mengindikasikan feature\n",
    "- X_train akan dikenakan proses transpose, dan hasil transpose akan ditampung dalam variabel X_train_transposed\n",
    "- Pada X_train_transposed terdiri dari dua baris\n",
    "- Baris pertama berkorelasi dengan nilai feature\n",
    "- Baris kedua merepresentasikan nilai untuk jenis kelamin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "automatic-declaration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jk: ['pria' 'pria' 'pria' 'pria' 'wanita' 'wanita' 'wanita' 'wanita' 'wanita']\n",
      "\n",
      "jk_binarised:\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "jk_binarised = lb.fit_transform(X_train_transposed[1])\n",
    "\n",
    "print(f'jk: {X_train_transposed[1]}\\n')\n",
    "print(f'jk_binarised:\\n{jk_binarised}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fallen-trance",
   "metadata": {},
   "source": [
    "- variabel lb menampung objek LabelBinarizer\n",
    "- lb.fit_transform(X_train_transposed[1]) agar tranposed LabelBinarizer diterapkan pada jenis kelamin\n",
    "- variabel jk_binarised menampung hasil tranform\n",
    "- Data pria adalah 0\n",
    "- Data wanita adalah 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "colored-ridge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jk_binarised = jk_binarised.flatten()\n",
    "jk_binarised"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mental-germany",
   "metadata": {},
   "source": [
    "- method flatten untuk mengkonversikan array multi dimensi menjadi array dimensi tunggal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "billion-large",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_transposed:\n",
      "[[158 170 183 191 155 163 180 158 170]\n",
      " [0 0 0 0 1 1 1 1 1]]\n",
      "\n",
      "X_train:\n",
      "[[158 0]\n",
      " [170 0]\n",
      " [183 0]\n",
      " [191 0]\n",
      " [155 1]\n",
      " [163 1]\n",
      " [180 1]\n",
      " [158 1]\n",
      " [170 1]]\n"
     ]
    }
   ],
   "source": [
    "X_train_transposed[1] = jk_binarised\n",
    "X_train = X_train_transposed.transpose()\n",
    "\n",
    "print(f'X_train_transposed:\\n{X_train_transposed}\\n')\n",
    "print(f'X_train:\\n{X_train}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coral-russian",
   "metadata": {},
   "source": [
    "- X_train_transposed akan di tranpose kembali agar yang tadi baris menjadi kolom, dan yang tadi kolom menjadi baris\n",
    "- Hasil tranpose akan ditampung pada variable X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minimal-shepherd",
   "metadata": {},
   "source": [
    "### Training KNN Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "august-voice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(n_neighbors=3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "K = 3\n",
    "model = KNeighborsRegressor(n_neighbors=K)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hundred-impact",
   "metadata": {},
   "source": [
    "- KNeighborsRegressor dipakai karena kita akan menggunakan KNN untuk regression\n",
    "- nilai parameter K digunakan untuk menentukan jumlah tetangga terdekat yang akan dilibatkan untuk proses prediksi\n",
    "- model.fit(X_train, y_train) digunakan sebagai method training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extraordinary-moderator",
   "metadata": {},
   "source": [
    "### Prediksi Berat Badan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "hybrid-inclusion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[155,   1]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = np.array([[155, 1]])\n",
    "X_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bright-capitol",
   "metadata": {},
   "source": [
    "- Prediksi berat badan berdasarkan data tinggi badan dan jenis kelamin\n",
    "- Tinggi badan 155 cm\n",
    "- Jenis kelamin wanita / 1\n",
    "- [[155,   1]] merupakan nilai feature yang akan di prediksi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "accepted-weight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([55.66666667])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_new)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scenic-planet",
   "metadata": {},
   "source": [
    "- model.predict digunakan untuk melakukan prediksi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "everyday-belief",
   "metadata": {},
   "source": [
    "### Evaluasi KNN Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fitted-turkey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test:\n",
      "[[168   0]\n",
      " [180   0]\n",
      " [160   1]\n",
      " [169   1]]\n",
      "\n",
      "y_test: [65 96 52 67]\n"
     ]
    }
   ],
   "source": [
    "X_test = np.array([[168, 0], [180, 0], [160, 1], [169, 1]])\n",
    "y_test = np.array([65, 96, 52, 67])\n",
    "\n",
    "print(f'X_test:\\n{X_test}\\n')\n",
    "print(f'y_test: {y_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "british-allergy",
   "metadata": {},
   "source": [
    "- testing set terdiri dari 4 data point\n",
    "- variabel X_test untuk menampung sekumpulan nilai features\n",
    "- variabel y_test untuk menampung sekumpulan nilai target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "funded-portal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([70.66666667, 79.        , 59.        , 70.66666667])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranking-monitor",
   "metadata": {},
   "source": [
    "- untuk data dengan tinggi badan 168 dan jenis kelamin pria diprediksi memiliki berat badan 70.66666667, sedangkan data yang diharapkan adalah 65\n",
    "- untuk data dengan tinggi badan 180 dan jenis kelamin pria diprediksi memiliki berat badan 79, sedangkan data yang diharapkan adalah 96\n",
    "- untuk data dengan tinggi badan 160 dan jenis kelamin wanita diprediksi memiliki berat badan 59, sedangkan data yang diharapkan adalah 59\n",
    "- untuk data dengan tinggi badan 169 dan jenis kelamin wanita diprediksi memiliki berat badan 70.66666667, sedangkan data yang diharapkan adalah 67"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solved-summit",
   "metadata": {},
   "source": [
    "#### Coefficient of Determination atau $R^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "declared-conviction",
   "metadata": {},
   "source": [
    "Referensi: https://en.wikipedia.org/wiki/Coefficient_of_determination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "instrumental-crack",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.6290565226735438\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'R-squared: {r_squared}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functional-amateur",
   "metadata": {},
   "source": [
    "- Hasil pengukuran matrik r2_score(y_test, y_pred) ditampung pada variabel r_squared\n",
    "- semakin nilai R-squared mendekati 1, semakin baik"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "textile-sarah",
   "metadata": {},
   "source": [
    "#### Mean Absolute Error (MAE) atau Mean Absolute Deviation (MAD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transparent-mumbai",
   "metadata": {},
   "source": [
    "$MAE$ is the average of the absolute values of the errors of the predictions.\n",
    "\n",
    "$MAE$ adalah nilai rata-rata dari absolute error dari prediksi\n",
    "\n",
    "$MAE = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|$\n",
    "\n",
    "- $yi$ merepresentasikan setiap nilai target pada testing set\n",
    "- $\\hat{y}_i$ merupakan nilai prediksi yang dihasilkan oleh model\n",
    "- jika nilai prediksi lebih kecil dari nilai yang seharusnya, maka akan bernilai positif\n",
    "- jika nilai prediksi lebih besar dari nilai yang seharusnya, maka akan bernilai negatif\n",
    "- absolute function akan menghilangkan nilai negatif\n",
    "\n",
    "Referensi: https://en.wikipedia.org/wiki/Mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "wired-finance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 8.333333333333336\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "MAE = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(f'MAE: {MAE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "western-joining",
   "metadata": {},
   "source": [
    "- untuk menggunakan mean_absolute_error, kita memanggil mean_absolute_error dan sertakan (y_test, y_pred) sebagai parameter\n",
    "- variabel MAE untuk menampung nilai mean_absolute_error\n",
    "- semakin kecil nilai MAE akan mengindikasi kualitas modal yang lebih baik"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informational-approach",
   "metadata": {},
   "source": [
    "#### Mean Squared Error (MSE) atau Mean Squared Deviation (MSD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "located-mozambique",
   "metadata": {},
   "source": [
    "$MSE$ is the average of the squares of the errors of the predictions.\n",
    "\n",
    "$MSE$ merupakan rata-rata dari error kuadrat untuk prediksi\n",
    "\n",
    "$MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$\n",
    "- $yi$ merepresentasikan setiap nilai target pada testing set\n",
    "- $\\hat{y}_i$ merupakan nilai prediksi yang dihasilkan oleh model\n",
    "- $^2$ untuk menghindari nilai negatif\n",
    "- n adalah jumlah data point\n",
    "\n",
    "Referensi: https://en.wikipedia.org/wiki/Mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "motivated-status",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 95.8888888888889\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "MSE = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f'MSE: {MSE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detected-hamburg",
   "metadata": {},
   "source": [
    "- untuk menggunakan mean_squared_error, kita memanggil mean_squared_error dan sertakan (y_test, y_pred) sebagai parameter\n",
    "- variabel MSE untuk menampung nilai mean_squared_error\n",
    "- semakin kecil nilai MSE akan mengindikasi kualitas modal yang lebih baik"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personalized-being",
   "metadata": {},
   "source": [
    "### Permasalahan Scaling pada Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "published-davis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[60.0, 40.01249804748511]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "# tinggi dalam milimeter\n",
    "X_train = np.array([[1700, 0], [1600, 1]])\n",
    "X_new = np.array([[1640, 0]])\n",
    "\n",
    "[euclidean(X_new[0], d) for d in X_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "typical-rendering",
   "metadata": {},
   "source": [
    "- Variabel X_train akan berisi sekumpulan nilai features untuk training set\n",
    "- Variabel X_new akan berisi sekumpulan data point yang akan di prediksi\n",
    "- euclidean untuk mengukur jarak untuk data point baru [1640, 0] terhdap kedua data point [[1700, 0], [1600, 1]] untuk training set\n",
    "- 60.0 merupakan jarak antara data point yang baru [1640, 0] dengan data point pertama [1700, 0]\n",
    "- 40.01249804748511 merupakan jarak antara data point yang baru [1640, 0] dengan data point kedua [1600, 1]\n",
    "- Data point yang baru lebih dekat dengan data point kedua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "emotional-burning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.06000000000000005, 1.0007996802557444]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tinggi dalam meter\n",
    "X_train = np.array([[1.7, 0], [1.6, 1]])\n",
    "X_new = np.array([[1.64, 0]])\n",
    "\n",
    "[euclidean(X_new[0], d) for d in X_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powerful-fight",
   "metadata": {},
   "source": [
    "- 0.06000000000000005 merupakan jarak antara data point yang baru [1.64, 0] dengan data point pertama [1.7, 0]\n",
    "- 1.0007996802557444 merupakan jarak antara data point yang baru [1.64, 0] dengan data point kedua [1.6, 1]\n",
    "- Data point baru lebih dekat dengan data point pertama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invisible-dealer",
   "metadata": {},
   "source": [
    "### Menerapkan Standard Scaler (Standard Score atau Z-Score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advance-boundary",
   "metadata": {},
   "source": [
    "Standardize features by removing the mean and scaling to unit variance.\n",
    "\n",
    "$z = \\frac{x - \\bar{x}}{S}$\n",
    "- $x$ merepresentasikan nilai features\n",
    "- $\\bar{x}$ merepresentasikan rata-rata nilai features\n",
    "- $S$ merepresentasikan nilai standar deviasi dari sekumpulan nilai features\n",
    "\n",
    "Referensi: https://en.wikipedia.org/wiki/Standard_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "separated-complaint",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "combined-integration",
   "metadata": {},
   "source": [
    "Variabel ss menampung objek dari kelas StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ordinary-rescue",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_scaled:\n",
      "[[ 1. -1.]\n",
      " [-1.  1.]]\n",
      "\n",
      "X_new_scaled: [[-0.2 -1. ]]\n",
      "\n",
      "jarak: [1.2, 2.154065922853802]\n"
     ]
    }
   ],
   "source": [
    "# tinggi dalam milimeter\n",
    "X_train = np.array([[1700, 0], [1600, 1]])\n",
    "X_train_scaled = ss.fit_transform(X_train)\n",
    "print(f'X_train_scaled:\\n{X_train_scaled}\\n')\n",
    "\n",
    "X_new = np.array([[1640, 0]])\n",
    "X_new_scaled = ss.transform(X_new)\n",
    "print(f'X_new_scaled: {X_new_scaled}\\n')\n",
    "\n",
    "jarak = [euclidean(X_new_scaled[0], d) for d in X_train_scaled]\n",
    "print(f'jarak: {jarak}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inner-reggae",
   "metadata": {},
   "source": [
    "- Variabel X_train_scaled untuk menampung hasil trasform dari ss.fit_transform yang dikenai pada (X_train)\n",
    "- Variabel X_new_scaled untuk menampung hasil tranform dari ss.transform yang dikenai pada (X_new)\n",
    "- euclidean untuk menghitung jarak dari X_train_scaled dan X_new_scaled\n",
    "- 1.2 merupakan jarak antara data point X_new_scaled [-0.2 -1. ] dengan data point pertama X_train_scaled [ 1. -1.]\n",
    "- 2.154065922853802 merupakan jarak antara data point X_new_scaled [-0.2 -1. ] dengan data point kedua X_train_scaled [-1.  1.]\n",
    "- Data point X_new_scaled lebih dekat dengan data point pertama X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "sound-mayor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_scaled:\n",
      "[[ 1. -1.]\n",
      " [-1.  1.]]\n",
      "\n",
      "X_new_scaled: [[-0.2 -1. ]]\n",
      "\n",
      "jarak: [1.2000000000000026, 2.1540659228538006]\n"
     ]
    }
   ],
   "source": [
    "# tinggi dalam meter\n",
    "X_train = np.array([[1.7, 0], [1.6, 1]])\n",
    "X_train_scaled = ss.fit_transform(X_train)\n",
    "print(f'X_train_scaled:\\n{X_train_scaled}\\n')\n",
    "\n",
    "X_new = np.array([[1.64, 0]])\n",
    "X_new_scaled = ss.transform(X_new)\n",
    "print(f'X_new_scaled: {X_new_scaled}\\n')\n",
    "\n",
    "jarak = [euclidean(X_new_scaled[0], d) for d in X_train_scaled]\n",
    "print(f'jarak: {jarak}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerical-disclaimer",
   "metadata": {},
   "source": [
    "- 1.2000000000000026 merupakan jarak antara data point X_new_scaled [-0.2 -1. ] dengan data point pertama X_train_scaled [ 1. -1.]\n",
    "- 2.1540659228538006 merupakan jarak antara data point X_new_scaled [-0.2 -1. ] dengan data point kedua X_train_scaled [-1.  1.]\n",
    "- Data point X_new_scaled lebih dekat dengan data point pertama X_train_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generic-xerox",
   "metadata": {},
   "source": [
    "### Menerapkan Features Scaling pada KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "academic-sandwich",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "accompanied-biography",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Set\n",
    "X_train = np.array([[158, 0], [170, 0], [183, 0], [191, 0], [155, 1], [163, 1],\n",
    "                    [180, 1], [158, 1], [170, 1]])\n",
    "\n",
    "y_train = np.array([64, 86, 84, 80, 49, 59, 67, 54, 67])\n",
    "\n",
    "# Test Set\n",
    "X_test = np.array([[168, 0], [180, 0], [160, 1], [169, 1]])\n",
    "y_test = np.array([65, 96, 52, 67])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "useful-commons",
   "metadata": {},
   "source": [
    "- X_train untuk menampung sekumpulan nilai features untuk training set\n",
    "- y_train untuk menampung sekumpulan nilai target untuk training set\n",
    "- X_test untuk menampung sekumpulan nilai features untuk testing set\n",
    "- y_test untuk menampung sekumpulan nilai target untuk testing set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twenty-symphony",
   "metadata": {},
   "source": [
    "#### Features Scaling (Standard Scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "coral-yellow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_scaled:\n",
      "[[-0.9908706  -1.11803399]\n",
      " [ 0.01869567 -1.11803399]\n",
      " [ 1.11239246 -1.11803399]\n",
      " [ 1.78543664 -1.11803399]\n",
      " [-1.24326216  0.89442719]\n",
      " [-0.57021798  0.89442719]\n",
      " [ 0.86000089  0.89442719]\n",
      " [-0.9908706   0.89442719]\n",
      " [ 0.01869567  0.89442719]]\n",
      "\n",
      "X_test_scaled:\n",
      "[[-0.14956537 -1.11803399]\n",
      " [ 0.86000089 -1.11803399]\n",
      " [-0.82260955  0.89442719]\n",
      " [-0.06543485  0.89442719]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled = ss.fit_transform(X_train)\n",
    "X_test_scaled = ss.transform(X_test)\n",
    "\n",
    "print(f'X_train_scaled:\\n{X_train_scaled}\\n')\n",
    "print(f'X_test_scaled:\\n{X_test_scaled}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thrown-invasion",
   "metadata": {},
   "source": [
    "- Variabel X_train_scaled untuk menampung hasil tranform ss.fit_transform yang dikenakan pada(X_train)\n",
    "- Variabel X_test_scaled untuk menampung hasil transform ss.transform yang dikenakan pada (X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norman-battle",
   "metadata": {},
   "source": [
    "#### Training & Evaluasi Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fleet-improvement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 7.583333333333336\n",
      "MSE: 85.13888888888893\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train)\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "MAE = mean_absolute_error(y_test, y_pred)\n",
    "MSE = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f'MAE: {MAE}')\n",
    "print(f'MSE: {MSE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foster-mills",
   "metadata": {},
   "source": [
    "- Objek model di traing dengan menggunakan model.fit dan disertakan (X_train_scaled, y_train) sebagai parameter\n",
    "- Variabel y_pred untuk menampung hasil prediksi dari model.predict(X_test_scaled)\n",
    "- Variabel MAE untuk menampung nilai eror dari mean_absolute_error(y_test, y_pred)\n",
    "- Variabel MSE untuk menampung nilai eror dari mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cloudy-stream",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
